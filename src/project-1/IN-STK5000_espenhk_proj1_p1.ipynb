{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN-STK5000 project 1, part 1\n",
    "## by Espen H. Kristensen (espenhk)\n",
    "\n",
    "### 2.1.1 $\\texttt{NameBanker.expected_utility}$\n",
    "\n",
    "Given a probability $p \\in [0,1]$ of our loan being paid back, we wish to find the expected return on investment. We'll use $a$ for the amount, $d$ for the duration of the loan, and $r=0.005$ as the monthly interest rate. Treating the \"win/lose\" (repaid/forfeited) value as a binomial random variable $X$ with $X=1$ for a repaid loan and $X=0$ for a forfeited one, we know the expected value is\n",
    "\n",
    "$$ E(X) = p $$\n",
    "\n",
    "That is, we will have $X=1$ (a repaid loan) $\\frac{p}{100} \\%$ of the time, and a forfeited one $\\frac{1-p}{100} \\%$ of the time. So, by adding the returns of the win/lose cases and scaling each term by the rate of occurrence ($p$ and $1-p$), we get a return R\n",
    "\n",
    "$$ R = p \\cdot (a \\cdot 1.005^d) + (1-p) \\cdot (-a) $$\n",
    "\n",
    "I've implemented $\\texttt{expected_utility}$ function in $\\texttt{name_banker.py}$ as follows. Note that $\\texttt{get_proba}$ has been hard-coded set to always return $p=0.8$ for this part of the exercise.\n",
    "\n",
    "Note on filenames: the file $\\texttt{name_banker.py}$ delivered alongside this contains the entire implementation as part 1 of the project is finished, so it will deviate slightly from the below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 37-65 name_banker.py\n",
    "# The expected utility of granting the loan or not. Here there are two actions:\n",
    "# action = 0 do not grant the loan\n",
    "# action = 1 grant the loan\n",
    "#\n",
    "# Make sure that you extract the length_of_loan from the\n",
    "# 2nd attribute of x. Then the return if the loan is paid off to you is amount_of_loan*(1 + rate)^length_of_loan\n",
    "# The return if the loan is not paid off is -amount_of_loan.\n",
    "def expected_utility(self, x, action):\n",
    "    duration = x[0]\n",
    "    amount = x[1]\n",
    "    paid_off = True\n",
    "    rate = self.rate\n",
    "    return_win = amount*(1+rate)**duration\n",
    "    return_loss = -amount\n",
    "    success_prob = self.get_proba()\n",
    "\n",
    "    expected_return = (success_prob*return_win +\n",
    "                       (1-success_prob)*return_loss)\n",
    "\n",
    "    # Assume purely that if we get expect anything more than\n",
    "    # the original amount back, we grant the loan. In practice,\n",
    "    # you'd likely have a margin so you're making at least say 5%\n",
    "    # on every loan\n",
    "    return_margin = 0\n",
    "    if (expected_return + return_margin) > amount:\n",
    "        action = 1\n",
    "    else:\n",
    "        action = 0\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, $\\texttt{get_best_action}$ simply calculates action using this function, and returns the action chosen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 54-60 name_banker.py\n",
    "# Return the best action. This is normally the one that maximises expected utility.\n",
    "# However, you are allowed to deviate from this if you can justify the reason.\n",
    "def get_best_action(self, x):\n",
    "    # dummy value, action will be set by expected_utility()\n",
    "    action=0\n",
    "    action = self.expected_utility(x, action)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the $\\texttt{name_banker.py}$ file for the rest of this implementation, but other than this and the hard-coded $\\texttt{get_proba}$ function there are no changes from the skeleton code. Running this program and varying the probabilities, I've generated the following test output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load test_lending_output.txt\n",
    "= Using NameBanker with probability p of a successful return\n",
    "== p=0.8\n",
    "Trial 1: 811671.63351\n",
    "Trial 2: 785167.647446\n",
    "Trial 3: 730726.926036\n",
    "== p=0.5\n",
    "Trial 1: 835328.181468\n",
    "Trial 2: 881273.321313\n",
    "Trial 3: 826356.885197\n",
    "== p=0.2\n",
    "Trial 1: 605824.790654\n",
    "Trial 2: 611672.643699\n",
    "Trial 3: 603023.393655\n",
    "== p=0.1\n",
    "Trial 1: 27313.5038378\n",
    "Trial 2: 43701.6061405\n",
    "Trial 3: 36418.0051171\n",
    "\n",
    "= Using RandomBanker\n",
    "Trial 1: 366147.424382\n",
    "Trial 2: 375869.218748\n",
    "Trial 3: 327109.889969\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In short, we see that even at a measly 20% successful repayments, our NameBanker outperforms the random banker by a steady margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 $\\texttt{NameBanker.fit} , \\texttt{NameBanker.predict_proba}$, comments on labelling\n",
    "\n",
    "$\\texttt{fit()}$: I've chosen to use a K-nearest neighbors classifier. After some testing it seems the results are fairly stable with any $k \\in [5, 100]$. A $k$ as high as 100 seems excessive, though, so the current implementation uses $k=20$. The fit function is implemented as follows, note that it doesn't return anything but saves to the instance variable $\\texttt{self.model}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 9-15 name_banker.py\n",
    "# Fit the model to the data.  You can use any model you like to do\n",
    "# the fit, however you should be able to predict all class\n",
    "# probabilities\n",
    "def fit(self, X, y):\n",
    "    self.data = [X, y]\n",
    "    self.model = KNeighborsClassifier(n_neighbors=20)\n",
    "    self.model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\texttt{predict_proba()}$: After fit is called, we have a $\\texttt{self.model}$ we can use to call its built-in $\\texttt{predict_proba}$ function, so our implementation pretty straight forward. Note that the function both saves to $\\texttt{self.proba}$, so it can be used with $\\texttt{get_proba}$, and returns the value itself, so you can do prediction and getting in one call to $\\texttt{predict_proba}$. The implementation is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 22-28 name_banker.py\n",
    "# Predict the probability of failure for a specific person with data x\n",
    "def predict_proba(self, x):\n",
    "    # data needs to be packed in a list, as the function expects a double array\n",
    "    prob = self.model.predict_proba([x])\n",
    "    # unpack, and we only need the first probability p, as the other one is (1-p)\n",
    "    self.proba = prob[0][0]\n",
    "    return self.proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments on labelling: We are missing information on how this data was collected. It is unclear whether these are data based on actual given and repaid/forfeited loans, or simply data generated by a (professional) bank's assessment of a number of loan applications. Thus, particularly not knowing how reliable this bank is in the case of the data coming from loan applicants, it's hard to say if the assessments we get based on the data are applicable in the real world or simply \"best-guess\" estimations. If the data is from loan applicants, we will have inherent bias from how the output data was estimated, which may or may not actually be accurate. If this data is off from the real-world outcome, no matter how good a classifier we generate it will always carry these problems with it. \n",
    "\n",
    "Of course, knowing these real-world outcomes may not be a trivial task, since it (a) requires access to payment data and not application forms, and (b) may not even exist yet if the loans haven't been granted or aren't yet repaid. Also, to collect data on outcomes given all variations of input might entail giving large numbers of loans even though our currently best classifier suggests it's a bad idea -- and good luck finding a bank that will risk giving away millions ''just to see''."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
